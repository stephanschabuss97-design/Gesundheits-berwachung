# MIDAS Voice Assistant â€“ Incremental Roadmap

Ziel: VollstÃ¤ndiger, modularer Voice- & Text-Assistent â€“ Record â†’ Transcribe â†’ Assistant â†’ TTS â†’ Playback.

---

## 0. Bootstrap Layer (Pre-Init)
- **Boot-Logger**: lÃ¤uft im `<head>`, speichert Fehler in `localStorage` (`midas_bootlog_v1`), fÃ¤ngt Syntax-/Promise-/CSP-Fehler.
- **Bootlog-Merge**: beim Appstart ins Touchlog integrieren (`midas_touchlog_vX`), danach lÃ¶schen.
- **Bootstrap Validator**: prÃ¼ft Supabase, (spÃ¤ter) Service Worker/PWA, AudioContext, KI-Session; Fehler â†’ Diagnose-Screen.
- **Bootstrap Finish**: setzt `midas-state="idle"`, Touchlog â€žBOOT OK â€“ vX.Y.Zâ€œ.

> Nice-to-have, darf den Voice-Flow nicht blockieren.

---

## 1. Frontend â€“ Voice Controller (Phase 1)
1. **Audio Capture Skeleton (done)**  
   MediaRecorder-Setup, States `idle â†’ listening`, Fehlerfallback, Test: Klick â†’ Blob im Log.
2. **Transcribe Integration (done)**  
   Upload zu `/api/midas-transcribe`, State `thinking`, Fehler zurÃ¼ck zu `idle`, Test: Transcript erscheint.
3. **Assistant Roundtrip (done)**  
   Transcript in Voice-History, Request an `/api/midas-assistant`, Antwort/Actions verarbeiten, History sauber halten.
4. **TTS Playback (done)**  
   Antwort â†’ `/api/midas-tts`, `<audio>` abspielen, Stop/Interrupt, Cleanup, JSON-Sauberkeit garantiert (keine `"reply"`/`"actions"`-Fragmente mehr in TTS).
5. **Glow-Ring Animation (done v1)**  
   Goldring + Aura reagieren auf Voice-Stati (`idle/listening/thinking/speaking`); beim Sprechen pulsiert der Ring mit der GPT-Audio-Amplitude (KITT-Style).
6. **Nadel als Voice-Trigger (done)**  
   Zentrales State-Icon löst den Voice-Chat aus; Tageszeit-Grüße folgen separat.).

---

## 2. Backend â€“ Edge Functions (Phase 2)
1. **midas-transcribe (done)** â€“ Whisper (gpt-4o-transcribe), CORS, Logging.
2. **midas-assistant (done)** â€“ System Prompt + Voice Mode, History & Session-ID.
3. **midas-tts (done)** â€“ OpenAI/ElevenLabs TTS, MP3/WebM, Fehler-Fallback mit Text.

---

## 3. Textchat Modul â€“ Assistant UI (Phase 3)
- **assistant-text-ui**: leichtes Chatfenster (Foodcoach-Style), History nur im RAM.
- **Foto-Upload (â€žFood Analyseâ€œ)**: Kamera-Icon, Upload â†’ `/midas-food-analyse`, optional â€žtrag einâ€œ.
- **Diktiermodus**: Web Speech API, offline-fÃ¤hig, fÃ¼r schnellen Input.

---

## 4. Datenaktionen â€“ Allowed Actions (Phase 4)
- Erlaubt: `IntakeSave`, `BPSave`, `BodySave`, `AddNote`, `OpenModule`, `AssistantDiagnostics`, `DoctorRouting`.
- Nicht erlaubt: Chat-Archiv, Code-Lesen, Self-Updates, Tech-Scans.

---

## 5. Copy Utilities (Phase 5)
- **Intake Copy Button**: kopiert Datum/Zeit/Wasser/Salz/Protein (fÃ¼r ErnÃ¤hrungs-Chats).

---

## 6. Termin- & Arztmodul (Phase 6)
- Terminliste, Arztkartei, Google-Maps-Routing (â€žBring mich zum Kardiologenâ€œ), Voice-Queries (â€žWann ist mein nÃ¤chster Termin?â€œ).

---

## 7. Zukunft / Optional (Phase 7)
- Streaming TTS, Wakeword (â€žMidas?â€œ), Offline-Fallback (Text), Health-Briefings (â€žDeine Woche warâ€¦â€œ), Wearables.

---

## 8. Commit-Strategie
Jede Phase = eigener Commit inkl. README-/Changelog-/QA-Notiz; Voice-Feature bleibt per Flag abschaltbar.

---

## NÃ¤chste Schritte
1. Glow-/Nadel-UX umsetzen (Phase 1.5/1.6).
2. (Optional) Bootstrapper/Logger (Phase 0) vorbereiten.
3. Textchat-UI (Phase 3) starten.
4. Actions & Terminmodul (Phase 4/6) vorbereiten.
5. Intake Copy Utility (Phase 5).

